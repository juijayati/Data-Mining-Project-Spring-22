{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from string import punctuation\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from constants import pubtator_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "def process_sentence(text):\n",
    "    text = text.replace('/', ' / ')\n",
    "    text = text.replace('.-', ' .- ')\n",
    "    text = text.replace(\"(\", \" ( \")\n",
    "    text = text.replace(\")\", \" ) \")\n",
    "    text = text.replace(\"-\",\" - \")\n",
    "    text = text.replace('.', ' . ')\n",
    "    text = text.replace('\\'', ' \\' ')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    tokens = [token for token in text.split() if token not in punctuation and token not in stop_words]\n",
    "    tokens = [token.lower() if not token.startswith(\"Gene_\") else token for token in tokens]\n",
    "    tokens = [lemmatizer.lemmatize(token) if not token.startswith(\"Gene_\") else token  for token in tokens]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of sentences:  236815\n",
      "[['recessive', 'dystrophic', 'epidermolysis', 'bullosa', 'rdeb', 'manifest', 'blistering', 'erosion', 'skin', 'mucous', 'membrane', 'due', 'mutation', 'Gene_1294'], ['the', 'scarring', 'driven', 'inflammatory', 'processes,', 'particularly', 'Gene_7039', 'signaling', 'pathways,', 'resulting', 'excess', 'synthesis', 'deposition', 'extracellular', 'matrix,', 'especially', 'collagen'], ['losartan,', 'angiotensin', 'ii', 'type', '1', 'receptor', 'antagonist,', 'inhibitor', 'Gene_7039', 'activity'], ['previous', 'preclinical', 'study', 'hypomorphic', 'Gene_12836', 'mouse', 'recapitulating', 'feature', 'rdeb', 'suggested', 'losartan', 'may', 'improve', 'clinical', 'feature', 'rdeb'], ['the', 'diagnosis', 'based', 'characteristic', 'clinical', 'feature', 'presence', 'biallelic', 'loss', 'function', 'mutation', 'Gene_1294'], ['objective:', 'this', 'study', 'intended', 'explore', 'regulatory', 'function', 'Gene_100133205', 'nasopharyngeal', 'carcinoma', 'npc'], ['methods:', 'mir', '26a', '5p', 'inhibitor,', 'mimic,', 'si', 'Gene_100133205', 'transfected', 'npc', 'cell'], ['qrt', 'pcr', 'employed', 'ass', 'mir', '26a', '5p', 'Gene_100133205', 'expression'], ['the', 'targeting', 'relationship', 'Gene_100133205', 'mir', '26a', '5p', 'analyzed', 'dual', 'luciferase', 'reporter', 'rna', 'immunoprecipitation', 'assay'], ['cell', 'counting', 'kit', '8', 'assay,', 'colony', 'formation', 'assay,', 'flow', 'cytometry', 'assay,', 'wound', 'healing', 'assay,', 'transwell', 'assay', 'vitro', 'angiogenesis', 'assay', 'adopted', 'evaluation', 'effect', 'Gene_100133205', 'mir', '26a', '5p', 'Gene_100133205', 'npc', 'cell', 'regarding', 'cell', 'proliferation,', 'apoptosis', 'cycle,', 'migration,', 'invasion,', 'angiogenesis']]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(pubtator_output)\n",
    "texts = data.text.to_numpy().tolist()\n",
    "sentences = []\n",
    "for text in texts:\n",
    "    sentences.extend(sent_tokenize(text))\n",
    "\n",
    "print(\"the number of sentences: \", len(sentences))\n",
    "\n",
    "sentences = [process_sentence(sent) for sent in sentences]\n",
    "print(sentences[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding loaded from ./WordVectors/Pretrained/bioconceptvec_word2vec_cbow.bin\n",
      "Time to load cbow embeddings in mins:  0.59\n",
      "embedding loaded from ./WordVectors/Pretrained/bioconceptvec_word2vec_skipgram.bin\n",
      "Time to load skipgram embeddings in mins:  0.66\n"
     ]
    }
   ],
   "source": [
    "from gensim.models  import KeyedVectors, Word2Vec\n",
    "from utils import load_embedding\n",
    "from time import time\n",
    "\n",
    "t = time()\n",
    "w2v_cbow_pt = load_embedding(\"./WordVectors/Pretrained/bioconceptvec_word2vec_cbow.bin\", binary=True)\n",
    "print(\"Time to load cbow embeddings in mins: \", round(((time() - t)/60.0),2))\n",
    "\n",
    "t = time()\n",
    "w2v_sg_pt = load_embedding(\"./WordVectors/Pretrained/bioconceptvec_word2vec_skipgram.bin\", binary=True)\n",
    "print(\"Time to load skipgram embeddings in mins: \", round(((time() - t)/60.0),2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train cbow embeddings in mins:  2.12\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "t = time()\n",
    "w2v_cbow = Word2Vec(min_count=5, window=10, vector_size=100, sample=0.001, alpha=0.025, negative=5, workers= cores - 1, epochs=10, sg = 0)\n",
    "w2v_cbow.build_vocab(sentences)\n",
    "w2v_cbow.wv.vectors_lockf = np.ones(len(w2v_cbow.wv))\n",
    "w2v_cbow.wv.intersect_word2vec_format(\"./WordVectors/Pretrained/bioconceptvec_word2vec_cbow.bin\", binary=True)\n",
    "w2v_cbow.train(sentences, total_examples= w2v_cbow.corpus_count, epochs=30)\n",
    "print(\"Time to train cbow embeddings in mins: \", round(((time() - t)/60.0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words:  33731\n",
      "['cell', 'expression', 'the', 'wound', 'healing', 'level', 'in', 'effect', 'protein', 'migration', 'tissue', 'cancer', 'role', 'study', 'significantly', 'increased', 'mouse', 'group', 'human', 'gene', 'result', 'assay', 'we', 'treatment', 'also', 'pathway', 'patient', 'growth', 'signaling', 'showed', 'may', 'proliferation', 'factor', 'activity', 'using', 'compared', 'invasion', 'fibroblast', 'mrna', 'tumor', 'activation', 'control', 'results:', 'skin', 'analysis', 'Gene_7422', 'found', 'western', 'function', 'used', 'day', 'decreased', 'collagen', 'inhibited', 'target', 'vitro', 'mechanism', 'epithelial', '1', 'bone', 'reduced', 'could', 'potential', 'formation', 'proliferation,', 'induced', 'inhibitor', 'associated', 'model', 'receptor', 'increase', 'normal', 'overexpression', 'vivo', 'cells,', 'demonstrated', '2', 'Gene_7039', 'via', 'these', 'inhibition', 'line', 'this', '0', 'response', 'repair', 'however,', 'Gene_7040', 'type', 'p', 'expressed', 'higher', 'process', 'methods:', 'rat', 'a', 'present', 'significant', 'well', 'endothelial']\n"
     ]
    }
   ],
   "source": [
    "vocab = list(w2v_cbow.wv.key_to_index)\n",
    "print(\"Total number of words: \", len(vocab))\n",
    "\n",
    "print(vocab[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train cbow embeddings in mins:  1.37\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "w2v_sg = Word2Vec(min_count=5, window=10, vector_size=100, sample=0.001, alpha=0.025, negative=5, workers= cores - 1, epochs=10, sg = 1)\n",
    "w2v_sg.build_vocab(sentences)\n",
    "w2v_sg.wv.vectors_lockf = np.ones(len(w2v_sg.wv))\n",
    "w2v_sg.wv.intersect_word2vec_format(\"./WordVectors/Pretrained/bioconceptvec_word2vec_cbow.bin\", binary=True)\n",
    "w2v_sg.train(sentences, total_examples= w2v_sg.corpus_count, epochs=30)\n",
    "print(\"Time to train cbow embeddings in mins: \", round(((time() - t)/60.0),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of genes in vocab:  9151\n"
     ]
    }
   ],
   "source": [
    "all_genes = [word for word in vocab if word.startswith(\"Gene_\")]\n",
    "\n",
    "print(\"Total number of genes in vocab: \", len(all_genes))\n",
    "\n",
    "#with open(\"GeneLists/all_genes.txt\",\"w\") as f:\n",
    "    #for gene in all_genes:\n",
    "        #f.write(gene + \"\\n\")\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the trained vectors \n",
    "w2v_cbow.wv.save_word2vec_format(\"./WordVectors/Computed/word2vec_cbow.bin\", binary = True)\n",
    "w2v_sg.wv.save_word2vec_format(\"./WordVectors/Computed/word2vec_skipgram.bin\", binary = True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c94c8a2b4a38d84c9d502ef75fc1564633a6cf3f568e3899ec7413ad0d1be19"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
